# Image-Super-Resolution
The goal of this project was to compare older, simpler convolutional neural network models to newer, more competitive transformer models on the problem of super-resolution. Using the Efficient Sub-pixel Convolutional Network for Super-resolution as our CNN and the Hybrid Attention Transformer as our transformer model, the team trained each network on the Flickr Faces High-Quality image dataset. It is shown that the transformer model generally outperforms the CNN on measurable factors such as peak signal-to-noise ratio. However, the subjective quality of the images produced by each network is similar. Further, training the convolutional network from scratch took under 6 hours and utilized around 35% of the total dataset, while doing the same for the HAT model took 8 hours and utilized only 10 images.

